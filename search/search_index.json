{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Resource Mapping with Drones \u00b6 About the Course \u00b6 Welcome! This is an introductory course on how to use small camera drones for aerial mapping of land and resources. You will learn all the skills necessary to create precisely surveyed maps using photogrammetry methods. We will cover all of the industries and applications where drone imagery maps are making big impacts on society. Students will learn how to become licensed drones pilots with the Federal Aviation Administration (FAA). Instructor Jeffrey Gillan, PhD I am a researcher at the University of Arizona and have been involved with aerial mapping and drones since 2011. Ever since, I have been using small drones to map and survey rangelands, forests, river corridors, wetlands, agriculture fields, and golf courses. I love helping others learn to use these powerful tools. Overview \u00b6 Let's begin the coarse with this engaging brief video, which explores the use of drones for generating 2D and 3D photographic maps. Throughout this class, you will acquire the skills to execute these technique proficiently. The video provides an essential overview of photographic mapping through drone technology, while also shedding light on the myriad industries harnessing its potential. Terminology \u00b6 Let's get some terminology straight. There are a lot of different ways to refer to a remote control aircraft. I use the term drone most often because this has become the defacto term in society. Most people understand what you mean when you say drone . There are a number of different acronyms used to refer to drones. Some differ depending on the industry, application, or context. But for the most part, the following acronyms are generally interchangeable. Unmmaned Aircraft (UA) This is an aircraft where the pilot is not onboard. It is piloted remotely, probably through radio signals. Unmanned Aerial Vehicle (UAV) This is the same thing as a UA Unmanned Aerial System (UAS) This term refers to the entire flying system, not just the aircraft itself. Other components of the system include the remote control, the pilot, GPS, IMU, cameras, etc. Uncrewed Aerial System (UAS) This is the gender neutral term for UAS Small Unmanned Aerial System (sUAS) This term refers to a specific weight class of UAV aircraft as designated by the FAA. To meet the definition of sUAS, aircraft need to weight less than 55 lbs on takeoff. Remotely Piloted Aircraft (RPA) This is just another term for a drone that does not seem to get much use nowadays. Advantages of the Drone Perspective \u00b6 Land and resources on the land (e.g., trees) can be observed and measured at various scales, from in-situ field measurements all the way to continental scale satellite imagery. Each of the scales has a unique spatial resolution (pixel size) and geographic extent. Field measurements can provide very detailed information on the land and resources, but usually across a small geographic extent. Conversely, satellite imagery can cover the globe but with coarser grain observations. Drone imagery provides a unqiue scale that fits somewhere between field and airplane imagery. Drone imagery is relatively easy and cheap to collect compared with airplane imagery Drone imagery can cover much larger areas compared with field measurements Drone imagery can observe and measure some vegetation and topographic characteristics better than field measurements. A great example is capturing the structure of a tree. This is very difficult to do with manual measurements. Drones are highly portable and can be carried almost anywhere Drone imagery is on-demand. As long as the weather is good, I can go out and collect imagery. Limitations of Drones \u00b6 Limited Geographic coverage : A single small drone can cover hundreds and perhaps up to a few thousand acres. To cover larger areas, you need an airplane or a satellite. Limited Flight Endurance (battery limitations) : Most multi-rotor drones can stay aloft for only 25-30 minutes. Legal limitations including flying height above the ground, line-of-sight requirements, no operations over people. Requires expertise to plan, collect, process, and analyze drone imagery maps Cost : Drone equipment, processing software, and digital storage can all be expensive Camera Drone Models \u00b6 There are many companies globally making many different drone models. There is an enormous range of capabilities and price points. The following are some popular drone models worth checking out. Select Drone Manufacturers DJI DJI, a China-based company, is the world leader in the production of consumer and professional drones for photographic mapping. They make the best equipment at the lowest prices. In 2013, DJI released the Phantom 1 multi-rotor drone which was one of the first consumer drones completely assembled and ready to fly. Autel Robotics Skydio Wingtra AgEagle Consumer Drone History The Parrot AR Drone (circa 2010)was considered the first ready-to-fly consumer multirotor drone. The DJI Phantom 1 made it's debut in 2013. This was followed up with the Phantom 2 Vision + (2014) which was one of the first drones to have an integrated camera. These early models kick- started the consumer drone industry. Camera Drone Types \u00b6 There are three basic drone types: Multi-rotors , Fixed-Wing , and VTOL Fixed-Wing . Each has advantages and disadvantages that should be considered before buying or acquiring. The following section lists some of the characteristics of each type. Usually Less Expensive to Buy Vertical Launch and Landing Shorter Flight Endurance Able to Map Smaller Areas Very Precise Flying Precise Control of Gimbal Angle Relatively Expensive Throw Launch Belly Crash Landing Longer Flight Endurance Able to map very large areas Less Precise Flying Less Control of Camera Angle (via gimbal) This video shows a Bat4 fixed-wing drone taking off from a runway in 2012. Thankfully, most fixed-wing drones are now smaller and can be launched by a single person. All the advantages of the fixed-wing with the ability of vertical take-off and landing. Unmanned Aircraft System \u00b6 The 'system' refers to the all of the additional components on and around the aircraft. There are a lot of interacting technologies that make drone mapping possible. At the center of system is you the operator. You will have a remote control and some kind of screen (e.g., Ipad) to communicate with the aircraft. The aircraft will have a camara or sensor, an SD card to record the images, flight batteries, a global navigation satellite sensor (GNSS) and intertial measurement unit (IMU). The GNSS is receiving signals from satellites orbiting the Earth to help the drone navigate autonomously. Additionally, the drone and the remote control may be connected (via radio) to a base station to improve the positioning of the aircraft. The remote control may also be connnected to cellular towers in order to get a basemap in your mapping application. This may seem a bit complex at first, but don't worry, we'll explain every component throughout this course. Drone Sensors \u00b6 The focus of this class is making photographic maps from drones, so the camera or sensor is at the center of everything we do. Drones are flying cameras! Many types of cameras are mountable on drones. We will cover the most common. RGB \u00b6 The most common is a red, green, blue (RGB) camera, which is the regular color camera that we all have used. Drones often come with an RGB camera integrated directly into the aircraft. That makes them very easy to use. Some more fancy drones allow you to swap out different camera types. Integrated RGB Camera on Phantom Multi-Spectral \u00b6 Multi-spectral cameras are very popular for drone mapping. Multi-spectral means that they collect specific wavelenghts of light including visible and near-infrared. One of the main applications for multi-spectral mapping is observing the health of vegetation in an agricultural or natural resource context. The Micasense Altum Multi-Spectral sensor with 5 bands (blue, green, red, red-edge, near infrared) Multispectral Sensor Manufacturers AgEagle Sentera Thermal \u00b6 Drone-mounted thermal infrared cameras are used to detect temperature or heat signatures across a landscape. This technology could be used to detect live animals or identify the temperature differences between different land features. For example, thermal imagery is very useful for decting surface water. Flir Thermal Sensor LiDAR (Light detection and ranging) \u00b6 LiDAR is a 3D mapping sensor that sends out pulses of light (usually in the near-infrared range) that reflect off the ground and return to the sensor. The return time is converted to distance and when done millions of times, can provide precise 3D maps of the landscape. The typical imagery products created from laser scanning are called point clouds. Velodyne LiDAR Sensor LiDAR Point Cloud Hyperspectral \u00b6 Hyperspectral imagery expands the concept of multi-spectral imagery. While multi-spectral imagery typical has 5 or 6 bands sensitive to specific regions of the electromagnetic, hyperspectral sensors can have hundreds or thousands of bands. Rich reflectance data provided by hyperspectral sensors can provide insights into plant physiology, mineralogy, and soil types. Companies like Headwall are manufacturing hyperspectral sensors that can be mounted on drones. Hyperspectral spectral signature for Headwall Nano Hyperspec. The sensor has 270 bands ranging from 400-1000 nanometers Camera Mounting \u00b6 Gimbal \u00b6 Many integrated drone cameras will come mounted on a gimbal. A gimbal is a device used to stabilize and control the movement of a camera. It typically consists of motorized axes that work together to keep the camera level and steady. Most gimbals have a range of tilt that can be controlled from the remote control. Remote Controlled Camera Gimbal Shock Mount \u00b6 Shock mounting is mounting the camera in a way that reduces the impact of vibrations or movement on the camera. It is not motorized nor can the user change the camera angle remotely. Shock Mount","title":"Introduction"},{"location":"#resource-mapping-with-drones","text":"","title":" Resource Mapping with Drones"},{"location":"#about-the-course","text":"Welcome! This is an introductory course on how to use small camera drones for aerial mapping of land and resources. You will learn all the skills necessary to create precisely surveyed maps using photogrammetry methods. We will cover all of the industries and applications where drone imagery maps are making big impacts on society. Students will learn how to become licensed drones pilots with the Federal Aviation Administration (FAA). Instructor Jeffrey Gillan, PhD I am a researcher at the University of Arizona and have been involved with aerial mapping and drones since 2011. Ever since, I have been using small drones to map and survey rangelands, forests, river corridors, wetlands, agriculture fields, and golf courses. I love helping others learn to use these powerful tools.","title":"About the Course"},{"location":"#overview","text":"Let's begin the coarse with this engaging brief video, which explores the use of drones for generating 2D and 3D photographic maps. Throughout this class, you will acquire the skills to execute these technique proficiently. The video provides an essential overview of photographic mapping through drone technology, while also shedding light on the myriad industries harnessing its potential.","title":"Overview"},{"location":"#terminology","text":"Let's get some terminology straight. There are a lot of different ways to refer to a remote control aircraft. I use the term drone most often because this has become the defacto term in society. Most people understand what you mean when you say drone . There are a number of different acronyms used to refer to drones. Some differ depending on the industry, application, or context. But for the most part, the following acronyms are generally interchangeable. Unmmaned Aircraft (UA) This is an aircraft where the pilot is not onboard. It is piloted remotely, probably through radio signals. Unmanned Aerial Vehicle (UAV) This is the same thing as a UA Unmanned Aerial System (UAS) This term refers to the entire flying system, not just the aircraft itself. Other components of the system include the remote control, the pilot, GPS, IMU, cameras, etc. Uncrewed Aerial System (UAS) This is the gender neutral term for UAS Small Unmanned Aerial System (sUAS) This term refers to a specific weight class of UAV aircraft as designated by the FAA. To meet the definition of sUAS, aircraft need to weight less than 55 lbs on takeoff. Remotely Piloted Aircraft (RPA) This is just another term for a drone that does not seem to get much use nowadays.","title":"Terminology"},{"location":"#advantages-of-the-drone-perspective","text":"Land and resources on the land (e.g., trees) can be observed and measured at various scales, from in-situ field measurements all the way to continental scale satellite imagery. Each of the scales has a unique spatial resolution (pixel size) and geographic extent. Field measurements can provide very detailed information on the land and resources, but usually across a small geographic extent. Conversely, satellite imagery can cover the globe but with coarser grain observations. Drone imagery provides a unqiue scale that fits somewhere between field and airplane imagery. Drone imagery is relatively easy and cheap to collect compared with airplane imagery Drone imagery can cover much larger areas compared with field measurements Drone imagery can observe and measure some vegetation and topographic characteristics better than field measurements. A great example is capturing the structure of a tree. This is very difficult to do with manual measurements. Drones are highly portable and can be carried almost anywhere Drone imagery is on-demand. As long as the weather is good, I can go out and collect imagery.","title":"Advantages of the Drone Perspective"},{"location":"#limitations-of-drones","text":"Limited Geographic coverage : A single small drone can cover hundreds and perhaps up to a few thousand acres. To cover larger areas, you need an airplane or a satellite. Limited Flight Endurance (battery limitations) : Most multi-rotor drones can stay aloft for only 25-30 minutes. Legal limitations including flying height above the ground, line-of-sight requirements, no operations over people. Requires expertise to plan, collect, process, and analyze drone imagery maps Cost : Drone equipment, processing software, and digital storage can all be expensive","title":"Limitations of Drones"},{"location":"#camera-drone-models","text":"There are many companies globally making many different drone models. There is an enormous range of capabilities and price points. The following are some popular drone models worth checking out. Select Drone Manufacturers DJI DJI, a China-based company, is the world leader in the production of consumer and professional drones for photographic mapping. They make the best equipment at the lowest prices. In 2013, DJI released the Phantom 1 multi-rotor drone which was one of the first consumer drones completely assembled and ready to fly. Autel Robotics Skydio Wingtra AgEagle Consumer Drone History The Parrot AR Drone (circa 2010)was considered the first ready-to-fly consumer multirotor drone. The DJI Phantom 1 made it's debut in 2013. This was followed up with the Phantom 2 Vision + (2014) which was one of the first drones to have an integrated camera. These early models kick- started the consumer drone industry.","title":"Camera Drone Models"},{"location":"#camera-drone-types","text":"There are three basic drone types: Multi-rotors , Fixed-Wing , and VTOL Fixed-Wing . Each has advantages and disadvantages that should be considered before buying or acquiring. The following section lists some of the characteristics of each type. Usually Less Expensive to Buy Vertical Launch and Landing Shorter Flight Endurance Able to Map Smaller Areas Very Precise Flying Precise Control of Gimbal Angle Relatively Expensive Throw Launch Belly Crash Landing Longer Flight Endurance Able to map very large areas Less Precise Flying Less Control of Camera Angle (via gimbal) This video shows a Bat4 fixed-wing drone taking off from a runway in 2012. Thankfully, most fixed-wing drones are now smaller and can be launched by a single person. All the advantages of the fixed-wing with the ability of vertical take-off and landing.","title":"Camera Drone Types"},{"location":"#unmanned-aircraft-system","text":"The 'system' refers to the all of the additional components on and around the aircraft. There are a lot of interacting technologies that make drone mapping possible. At the center of system is you the operator. You will have a remote control and some kind of screen (e.g., Ipad) to communicate with the aircraft. The aircraft will have a camara or sensor, an SD card to record the images, flight batteries, a global navigation satellite sensor (GNSS) and intertial measurement unit (IMU). The GNSS is receiving signals from satellites orbiting the Earth to help the drone navigate autonomously. Additionally, the drone and the remote control may be connected (via radio) to a base station to improve the positioning of the aircraft. The remote control may also be connnected to cellular towers in order to get a basemap in your mapping application. This may seem a bit complex at first, but don't worry, we'll explain every component throughout this course.","title":"Unmanned Aircraft System"},{"location":"#drone-sensors","text":"The focus of this class is making photographic maps from drones, so the camera or sensor is at the center of everything we do. Drones are flying cameras! Many types of cameras are mountable on drones. We will cover the most common.","title":"Drone Sensors"},{"location":"#rgb","text":"The most common is a red, green, blue (RGB) camera, which is the regular color camera that we all have used. Drones often come with an RGB camera integrated directly into the aircraft. That makes them very easy to use. Some more fancy drones allow you to swap out different camera types. Integrated RGB Camera on Phantom","title":"RGB"},{"location":"#multi-spectral","text":"Multi-spectral cameras are very popular for drone mapping. Multi-spectral means that they collect specific wavelenghts of light including visible and near-infrared. One of the main applications for multi-spectral mapping is observing the health of vegetation in an agricultural or natural resource context. The Micasense Altum Multi-Spectral sensor with 5 bands (blue, green, red, red-edge, near infrared) Multispectral Sensor Manufacturers AgEagle Sentera","title":"Multi-Spectral"},{"location":"#thermal","text":"Drone-mounted thermal infrared cameras are used to detect temperature or heat signatures across a landscape. This technology could be used to detect live animals or identify the temperature differences between different land features. For example, thermal imagery is very useful for decting surface water. Flir Thermal Sensor","title":"Thermal"},{"location":"#lidar-light-detection-and-ranging","text":"LiDAR is a 3D mapping sensor that sends out pulses of light (usually in the near-infrared range) that reflect off the ground and return to the sensor. The return time is converted to distance and when done millions of times, can provide precise 3D maps of the landscape. The typical imagery products created from laser scanning are called point clouds. Velodyne LiDAR Sensor LiDAR Point Cloud","title":"LiDAR (Light detection and ranging)"},{"location":"#hyperspectral","text":"Hyperspectral imagery expands the concept of multi-spectral imagery. While multi-spectral imagery typical has 5 or 6 bands sensitive to specific regions of the electromagnetic, hyperspectral sensors can have hundreds or thousands of bands. Rich reflectance data provided by hyperspectral sensors can provide insights into plant physiology, mineralogy, and soil types. Companies like Headwall are manufacturing hyperspectral sensors that can be mounted on drones. Hyperspectral spectral signature for Headwall Nano Hyperspec. The sensor has 270 bands ranging from 400-1000 nanometers","title":"Hyperspectral"},{"location":"#camera-mounting","text":"","title":"Camera Mounting"},{"location":"#gimbal","text":"Many integrated drone cameras will come mounted on a gimbal. A gimbal is a device used to stabilize and control the movement of a camera. It typically consists of motorized axes that work together to keep the camera level and steady. Most gimbals have a range of tilt that can be controlled from the remote control. Remote Controlled Camera Gimbal","title":"Gimbal"},{"location":"#shock-mount","text":"Shock mounting is mounting the camera in a way that reduces the impact of vibrations or movement on the camera. It is not motorized nor can the user change the camera angle remotely. Shock Mount","title":"Shock Mount"},{"location":"Drone_Mapping_Applications/","text":"Plant Agriculture \u00b6 Rangeland Management \u00b6 Drone imagery mapping can provide many types of data useful for rangeland management and monitoring: Vegetation cover and composition Estimating forage utilization Calculating percentage of bare ground and size of canpy gaps Estimating forage and woody biomass Cattle grazing at the Santa Rita Range in southern Arizona Photogrammetric point cloud depicting forage utilization Examples From the Literature Integrating drone imagery with existing rangeland monitoring programs Innovations to expand drone data collection and analysis for rangelands A pilot study to estimate forage mass from unmanned aerial vehicles in a semi-arid rangeland Construction \u00b6 Civil Engineering \u00b6 Forestry \u00b6 Mining \u00b6 Geology/Volcanology \u00b6 Marine Environments \u00b6 Rivers & Wetlands \u00b6 Topographic Change \u00b6 Wildlife Surveys \u00b6 Archaelogy \u00b6 Disaster Management \u00b6","title":"Drone Mapping Applications"},{"location":"Drone_Mapping_Applications/#plant-agriculture","text":"","title":"Plant Agriculture"},{"location":"Drone_Mapping_Applications/#rangeland-management","text":"Drone imagery mapping can provide many types of data useful for rangeland management and monitoring: Vegetation cover and composition Estimating forage utilization Calculating percentage of bare ground and size of canpy gaps Estimating forage and woody biomass Cattle grazing at the Santa Rita Range in southern Arizona Photogrammetric point cloud depicting forage utilization Examples From the Literature Integrating drone imagery with existing rangeland monitoring programs Innovations to expand drone data collection and analysis for rangelands A pilot study to estimate forage mass from unmanned aerial vehicles in a semi-arid rangeland","title":"Rangeland Management"},{"location":"Drone_Mapping_Applications/#construction","text":"","title":"Construction"},{"location":"Drone_Mapping_Applications/#civil-engineering","text":"","title":"Civil Engineering"},{"location":"Drone_Mapping_Applications/#forestry","text":"","title":"Forestry"},{"location":"Drone_Mapping_Applications/#mining","text":"","title":"Mining"},{"location":"Drone_Mapping_Applications/#geologyvolcanology","text":"","title":"Geology/Volcanology"},{"location":"Drone_Mapping_Applications/#marine-environments","text":"","title":"Marine Environments"},{"location":"Drone_Mapping_Applications/#rivers-wetlands","text":"","title":"Rivers &amp; Wetlands"},{"location":"Drone_Mapping_Applications/#topographic-change","text":"","title":"Topographic Change"},{"location":"Drone_Mapping_Applications/#wildlife-surveys","text":"","title":"Wildlife Surveys"},{"location":"Drone_Mapping_Applications/#archaelogy","text":"","title":"Archaelogy"},{"location":"Drone_Mapping_Applications/#disaster-management","text":"","title":"Disaster Management"},{"location":"classification/","text":"Photogrammetric Point Cloud Remotely Sensed Changes in Vegetation Cover Distribution and Groundwater along the Lower Gila River UAV in the advent of the twenties: Where we stand and what is next Mapping Forested Wetland Inundation in the Delmarva Peninsula, USA Using Deep Convolutional Neural Networks Automatic recognition of soybean leaf diseases using UAV images and deep convolutional neural networks Fruit detection and 3D location using instance segmentation neural networks and structure-from-motion photogrammetry Disaster damage detection through synergistic use of deep learning and 3D point cloud features derived from very high resolution oblique aerial images, and multiple-kernel-learning Semantic Segmentation Object Detection Instance Segmentation Jensen, J.R., 2016, Introductory Digital Image Processing: A Remote Sensing Perspective, Boston: Pearson Education, Inc., 623 p. Pixels Unclassified Objects","title":"Classification"},{"location":"cloud_native/","text":"Cloud Native \u00b6","title":"Cloud Native"},{"location":"cloud_native/#cloud-native","text":"","title":"Cloud Native"},{"location":"drone_legality/","text":"Drone Registration \u00b6 sUAS Part 107 Remote Pilot Certificate \u00b6 Part 107 Regulations \u00b6 Aircraft Size \u00b6 Visual Line of Sight \u00b6 Operations Over People \u00b6 Night Operations \u00b6 Operating Limitations \u00b6 Remote ID \u00b6 Special Waivers \u00b6 Airspace Designations \u00b6 Sectional Charts \u00b6 NOTAMs and TFRs \u00b6 Controlled Airspace Permissions \u00b6 B4UFly App \u00b6 Statute v. Nautical Miles \u00b6","title":"Drone Legality"},{"location":"drone_legality/#drone-registration","text":"","title":"Drone Registration"},{"location":"drone_legality/#suas-part-107-remote-pilot-certificate","text":"","title":"sUAS Part 107 Remote Pilot Certificate"},{"location":"drone_legality/#part-107-regulations","text":"","title":"Part 107 Regulations"},{"location":"drone_legality/#aircraft-size","text":"","title":"Aircraft Size"},{"location":"drone_legality/#visual-line-of-sight","text":"","title":"Visual Line of Sight"},{"location":"drone_legality/#operations-over-people","text":"","title":"Operations Over People"},{"location":"drone_legality/#night-operations","text":"","title":"Night Operations"},{"location":"drone_legality/#operating-limitations","text":"","title":"Operating Limitations"},{"location":"drone_legality/#remote-id","text":"","title":"Remote ID"},{"location":"drone_legality/#special-waivers","text":"","title":"Special Waivers"},{"location":"drone_legality/#airspace-designations","text":"","title":"Airspace Designations"},{"location":"drone_legality/#sectional-charts","text":"","title":"Sectional Charts"},{"location":"drone_legality/#notams-and-tfrs","text":"","title":"NOTAMs and TFRs"},{"location":"drone_legality/#controlled-airspace-permissions","text":"","title":"Controlled Airspace Permissions"},{"location":"drone_legality/#b4ufly-app","text":"","title":"B4UFly App"},{"location":"drone_legality/#statute-v-nautical-miles","text":"","title":"Statute v. Nautical Miles"},{"location":"flight_mission_planning/","text":"This module will cover the basics of how to collect drone imagery for photographic mapping purposes. The topics include: Physical camera characteristics Aerial Imagery Scale Principles of Stereo Photography Autonomous Mission Planning Camera Characteristics \u00b6 Focal Length & Field of View \u00b6 Inside the camera, the Focal Length is the distance from the lens to the sensor plane (usually reported in mm) The camera field of view (FOV) , also called the angle of view, is the extent of the observable world that can be seen at any give moment. FOV is typically reported in degrees and can vary greatly between lens and camera types. Typically a camera with a longer focal length will have a narrower FOV and a camera with a shorter focal length will have a wider FOV. Drone cameras often have a fairly wide FOV because they are meant to capture landscapes. The graphic below shows the relationship between focal length and FOV. Highlighted is the DJI Phantom 4 multi-rotor drone. Sensor Array \u00b6 Digital cameras have a sensor array of millions of tiny photosites (corresponding to pixels) that are each sensitive to light. The physical size (width and height in mm) as well as the number of photosites can vary between sensors. The graphic below shows the sensor array of the Phantom 4 camera. Multiplying the number of photosites (pixels) wide by the number of photosites high will tell you the total number of photosites for the array. In our example, the camera has 19.9 million pixels, which are also called megapixels. Sensor Array Aerial Imagery Scale \u00b6 In traditional aerial photography, scale was defined as the ratio of the distance between two points on an image to the actual distance between the same two points on the ground . Scale was generally reported as 1:25,000 or similar. So if I had a printed aerial photograph and measured the distance between two objects to be 0.25 inches and the scale was 1:25,000, the real world distance between the objects would be 6250 inches (0.25 x 25,000) or 520.8 feet. However, with the advent of fully digital aerial photography workflows and the computer screen being the primary tool for viewing imagery, the traditional concept of reporting scale is less useful. When it comes to drone imagery scale, the two important concepts to understand are image footprint and ground sampling distance . Image Footprint is the rectangular ground area that is captured by a camera exposure. Ground Sampling Distance (GSD) is the width of area on the ground that is captured by one pixel. It is also commonly referred to as pixel size or spatial resolution . For example, a pixel that captures an area of 2 x 2 cm (4 cm 2 ) is said to have a GSD of 2 cm. As a drone camera gets higher in the sky (further away from the ground), the image footprint and GSD get larger. We can calculate the image footprint and GSD with simple formulas that include the camera physical characteristics and flying height. Image Footprint and GSD Calculator Pix4D has a nice GSD calculator tool to calculate image dimensions and pixel ground sampling distance based on your drone specs Check out this video which describes how to calculate GSD of aerial images Stereo Aerial Photography \u00b6 Photographic mapping from drones requires overlapping imagery. That is, as the drone is flying and taking pictures, the image footprints should overlap. Overlap is usually reported as a percentage (%). Forward overlap is the overlap % from successive image footprints. Side overlap is the overlap % from adjacent flight lines. For robust photogrammetry, it is recommended to have forward overlap of 70%-85% and side overlap of 70%-80% . But these are not hard and fast rules, just recommendations. Optimal overlap will differ depending on the landscape you are imaging and your goal for your imagery products. Footprint overlap means that any given location on the ground is being imaged from multiple perspectives. In the example graphic below, the shrub is being imaged from 6 different perpective views. Autonomous Mission Planning \u00b6 The most efficient way to collect overlapping drone imagery of a landscape is to plan and execute an autonomous flight plan . Nearly all modern drones have software applications that empower you program the drone to capture imagery of an area interest - all automatically! Please check out the following video for an example of autonomous mission planning. All autonomous planning and flying apps will be slightly different from each other, but the basics are generally universal. It can be as simple as tapping a bounding box, selecting a few user parameters, and launching the drone! Autonomous planning and flying apps generally have a suite of user-defined parameters that enable you to customize your flight. These parameters include: A box or polygon designating the area to be imaged Flying height (m) Ground sampling distance (cm) Forward overlap (%) and side overlap (%) Flying speed (m/s) Gimbal angle Based on the user-defined parameters, the mapping software will compute the following: Exact flying route including the number and spacing of flight lines Timing between exposures Calculate Number of Images per Flight Line Calculate Number of Flight Lines for a Flight Area Double v Single Grid \u00b6 Double Grid Advantages: Better photographic coverage leading to better 3D modeling Double Grid Disadvantages: Longer flight times; larger datasets that take longer to process Oblique Imagery \u00b6 Aerial mapping is typically vertical (nadir) but oblique images can also be used in photogrammetry. The addition of oblique images ca improve photogrammetry solutions and improve 3D point clouds at the base of vertical objects GSD Recommendations \u00b6 Features of interest should drive the optimal GSD; detecting (and 3D modeling) small objects requires finer GSD; Coarser GSD will lead to coarser 3D modeling Mission planning Tips \u00b6 Collect imagery with pre-programmed autonomous flights. Don\u2019t try to collect imagery with manual flying! Make your flight areas into simple polygons like rectangles. Don\u2019t draw complicated flight areas. Make the flight polygon bigger than your area of interest by 10-15%. The periphery of imagery products are often of less quality. Small alterations to flying height and polygon size can make a big difference in how long the total mission takes Always plan flights around quantity and endurance of your flight batteries Camera Settings \u00b6 Exposure Triangle \u00b6 White Balance \u00b6 White balance: never use automatic white balance! Images will have different hues. Set camera to 'sunny' or 'cloudy'","title":"Flight Mission Planning"},{"location":"flight_mission_planning/#camera-characteristics","text":"","title":"Camera Characteristics"},{"location":"flight_mission_planning/#focal-length-field-of-view","text":"Inside the camera, the Focal Length is the distance from the lens to the sensor plane (usually reported in mm) The camera field of view (FOV) , also called the angle of view, is the extent of the observable world that can be seen at any give moment. FOV is typically reported in degrees and can vary greatly between lens and camera types. Typically a camera with a longer focal length will have a narrower FOV and a camera with a shorter focal length will have a wider FOV. Drone cameras often have a fairly wide FOV because they are meant to capture landscapes. The graphic below shows the relationship between focal length and FOV. Highlighted is the DJI Phantom 4 multi-rotor drone.","title":"Focal Length &amp; Field of View"},{"location":"flight_mission_planning/#sensor-array","text":"Digital cameras have a sensor array of millions of tiny photosites (corresponding to pixels) that are each sensitive to light. The physical size (width and height in mm) as well as the number of photosites can vary between sensors. The graphic below shows the sensor array of the Phantom 4 camera. Multiplying the number of photosites (pixels) wide by the number of photosites high will tell you the total number of photosites for the array. In our example, the camera has 19.9 million pixels, which are also called megapixels. Sensor Array","title":"Sensor Array"},{"location":"flight_mission_planning/#aerial-imagery-scale","text":"In traditional aerial photography, scale was defined as the ratio of the distance between two points on an image to the actual distance between the same two points on the ground . Scale was generally reported as 1:25,000 or similar. So if I had a printed aerial photograph and measured the distance between two objects to be 0.25 inches and the scale was 1:25,000, the real world distance between the objects would be 6250 inches (0.25 x 25,000) or 520.8 feet. However, with the advent of fully digital aerial photography workflows and the computer screen being the primary tool for viewing imagery, the traditional concept of reporting scale is less useful. When it comes to drone imagery scale, the two important concepts to understand are image footprint and ground sampling distance . Image Footprint is the rectangular ground area that is captured by a camera exposure. Ground Sampling Distance (GSD) is the width of area on the ground that is captured by one pixel. It is also commonly referred to as pixel size or spatial resolution . For example, a pixel that captures an area of 2 x 2 cm (4 cm 2 ) is said to have a GSD of 2 cm. As a drone camera gets higher in the sky (further away from the ground), the image footprint and GSD get larger. We can calculate the image footprint and GSD with simple formulas that include the camera physical characteristics and flying height. Image Footprint and GSD Calculator Pix4D has a nice GSD calculator tool to calculate image dimensions and pixel ground sampling distance based on your drone specs Check out this video which describes how to calculate GSD of aerial images","title":"Aerial Imagery Scale"},{"location":"flight_mission_planning/#stereo-aerial-photography","text":"Photographic mapping from drones requires overlapping imagery. That is, as the drone is flying and taking pictures, the image footprints should overlap. Overlap is usually reported as a percentage (%). Forward overlap is the overlap % from successive image footprints. Side overlap is the overlap % from adjacent flight lines. For robust photogrammetry, it is recommended to have forward overlap of 70%-85% and side overlap of 70%-80% . But these are not hard and fast rules, just recommendations. Optimal overlap will differ depending on the landscape you are imaging and your goal for your imagery products. Footprint overlap means that any given location on the ground is being imaged from multiple perspectives. In the example graphic below, the shrub is being imaged from 6 different perpective views.","title":"Stereo Aerial Photography"},{"location":"flight_mission_planning/#autonomous-mission-planning","text":"The most efficient way to collect overlapping drone imagery of a landscape is to plan and execute an autonomous flight plan . Nearly all modern drones have software applications that empower you program the drone to capture imagery of an area interest - all automatically! Please check out the following video for an example of autonomous mission planning. All autonomous planning and flying apps will be slightly different from each other, but the basics are generally universal. It can be as simple as tapping a bounding box, selecting a few user parameters, and launching the drone! Autonomous planning and flying apps generally have a suite of user-defined parameters that enable you to customize your flight. These parameters include: A box or polygon designating the area to be imaged Flying height (m) Ground sampling distance (cm) Forward overlap (%) and side overlap (%) Flying speed (m/s) Gimbal angle Based on the user-defined parameters, the mapping software will compute the following: Exact flying route including the number and spacing of flight lines Timing between exposures Calculate Number of Images per Flight Line Calculate Number of Flight Lines for a Flight Area","title":"Autonomous Mission Planning"},{"location":"flight_mission_planning/#double-v-single-grid","text":"Double Grid Advantages: Better photographic coverage leading to better 3D modeling Double Grid Disadvantages: Longer flight times; larger datasets that take longer to process","title":"Double v Single Grid"},{"location":"flight_mission_planning/#oblique-imagery","text":"Aerial mapping is typically vertical (nadir) but oblique images can also be used in photogrammetry. The addition of oblique images ca improve photogrammetry solutions and improve 3D point clouds at the base of vertical objects","title":"Oblique Imagery"},{"location":"flight_mission_planning/#gsd-recommendations","text":"Features of interest should drive the optimal GSD; detecting (and 3D modeling) small objects requires finer GSD; Coarser GSD will lead to coarser 3D modeling","title":"GSD Recommendations"},{"location":"flight_mission_planning/#mission-planning-tips","text":"Collect imagery with pre-programmed autonomous flights. Don\u2019t try to collect imagery with manual flying! Make your flight areas into simple polygons like rectangles. Don\u2019t draw complicated flight areas. Make the flight polygon bigger than your area of interest by 10-15%. The periphery of imagery products are often of less quality. Small alterations to flying height and polygon size can make a big difference in how long the total mission takes Always plan flights around quantity and endurance of your flight batteries","title":"Mission planning Tips"},{"location":"flight_mission_planning/#camera-settings","text":"","title":"Camera Settings"},{"location":"flight_mission_planning/#exposure-triangle","text":"","title":"Exposure Triangle"},{"location":"flight_mission_planning/#white-balance","text":"White balance: never use automatic white balance! Images will have different hues. Set camera to 'sunny' or 'cloudy'","title":"White Balance"},{"location":"flight_operations/","text":"","title":"Flight Operations"},{"location":"imagery_products/","text":"Point Clouds \u00b6 Digital Elevation Models \u00b6 Digital Surface Models (DSMs) \u00b6 Digital Terrain Models (DTMs) \u00b6 Orthomosaic \u00b6","title":"Imagery Products"},{"location":"imagery_products/#point-clouds","text":"","title":"Point Clouds"},{"location":"imagery_products/#digital-elevation-models","text":"","title":"Digital Elevation Models"},{"location":"imagery_products/#digital-surface-models-dsms","text":"","title":"Digital Surface Models (DSMs)"},{"location":"imagery_products/#digital-terrain-models-dtms","text":"","title":"Digital Terrain Models (DTMs)"},{"location":"imagery_products/#orthomosaic","text":"","title":"Orthomosaic"},{"location":"multi_spectral/","text":"","title":"Multi Spectral"},{"location":"natural_resource/","text":"","title":"Natural Resource Applications"},{"location":"photogrammetry/","text":"","title":"Photogrammetry"},{"location":"referencing/","text":"","title":"Referencing"},{"location":"images/crap/","text":"","title":"Crap"}]}